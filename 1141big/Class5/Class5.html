<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Class 5</title>
    <!-- MathJax Configuration -->
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <!-- Load MathJax -->
    <script id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
    </script>

    <!-- Load Marked.js for Markdown parsing -->
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        /* General Styling */
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background: #f4f4f9; /* Light Gray Background */
            color: #333;
        }

        /* Navigation Bar at TOP*/
        nav {
            background-color: #3498db; /* Blue Background */
            color: white;
            padding: 10px 20px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        nav h1 {
            margin: 0;
            font-size: 24px;
        }
        nav ul {
            list-style: none;
            margin: 0;
            padding: 0;
            display: flex;
            gap: 20px;
        }
        nav ul li {
            display: inline;
        }
        nav ul li a {
            color: white;
            text-decoration: none;
            font-size: 18px;
            transition: color 0.3s ease;
        }
        nav ul li a:hover {
            color: #ecf0f1; /* Lighter White on Hover */
        }

        /* Section Styling */
        section {
            width: 80%;
            max-width: 900px;
            margin: 50px auto;
            padding: 20px;
            background: white;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            text-align: left;
        }
        h1, h2, h3 {
            color: #34495e;
        }
        p, li {
            font-size: 18px;
            line-height: 1.6;
            color: #555;
        }
        pre {
            background-color: #f9f9f9;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-size: 14px;
        }
        code {
            color: #e74c3c;
        }

        /* 兩種div的定義：Summary and Discussion */
        .summary {
            background-color: #ecf0f1;
            padding: 15px;
            border-left: 5px solid #3498db;
            text-align: left;
        }
        .discussion {
            background-color: #fef9e7;
            padding: 15px;
            border-left: 5px solid #f1c40f;
            text-align: left;
        }
    </style>
</head>
<body>

<!-- Navigation Bar -->
<nav>
    <h1>Class 5 Ensemble Learning</h1>
    <ul> <!-- NAV BAR在上面, 要跟下面的大 section們有連接 , -->
        <li><a href="#introduction">Introduction</a></li>
        <li><a href="#topic1">Bagging Algorithms</a></li>
        <li><a href="#topic2">Boosting Algorithms</a></li>
        <li><a href="#topic3">Stacking Ensemble</a></li>
    </ul>
</nav>

<!-- Introduction Section -->
 <section id="Introduction">
    <div class="discussion">
    <h1>Today's Topic</h1>
    <ol>
        <li>Bagging Algorithms and Random Forest Algorithm</li>
        <li>Boosting Algorithms and AdaBoost Algorithms</li>
        <li>Stacking Ensemble</li>
    </ol> 
</div>
</section>

<section id="introduction">
    <div class="summary">
    <h1>Introduction</h1>
    <p><small>
      “United we stand” is the motto for ensemble methods. 
      We have discussed and experimented with several supervised learning methods and learned how to evaluate them 
      and tune their performance. 
      Ensemble learning is a suite of techniques that uses multiple machine learning models 
      in order to obtain better performance than we could have from any of the models.<br>
      Ensemble learning allows us to collate the power of multiple models and then make a prediction. 
      These models individually are weak but together act as a strong model for prediction
    </small></p>
    <img src="images\2025063001.jpg" alt="2025063001" width="300">
    <p><small>
       Ensemble methods can be divided into two broad categories: bagging and boosting
       <ul>
        <li>Bagging uses sampling with replacement to generate multiple datasets. 
            It builds multiple predictors simultaneously and independently of each other</li>
        <li>In boosting, the learners are grown sequentially from the last one. 
            Each subsequent learner improves from the last iteration and focuses more on the errors in the last iteration</li>
       </ul> 
    </small></p>
</div>
</section>


<section id="topic1">
<div class="summary">
    <h1>Bagging (Bootstrap Aggregating) Algorithms</h1>
    <p><small>
       <mark>Bagging</mark> is an ensemble machine learning technique designed to improve the stability and accuracy of algorithms 
       by combining multiple models. It works by: 
       <ul>
        <li>Creating multiple bootstrap samples (random samples with replacement) from the original datase</li>
        <li>Training a base model on each bootstrap sample</li>
        <li>Aggregating predictions through voting (classification) or averaging (regression)</li>
       </ul>
    </small></p>
    <h2>Random Forest</h2>
    <p><small>
       Random forest algorithm is an `ensemble method` and creates decision trees by using <mark>data resampling</mark> 
       and then gets the prediction from each of them and finally selects the best solution by means of voting or averaging.<br>
       A forest is made up of trees and more trees means more robust forest. 
       Random forest algorithm creates decision trees on data samples and then gets the prediction from each of them and finally selects the best solution by means of voting or averaging.
    </small></p>
    <p><small>
       Decision trees are constructed by selecting one of the attributes that provides the best separation of the classes. 
       This is done either by computing the information gain or Gini index.  
    </small></p>
    <img src="images\2025063002.jpg" alt="2025063002" width="300">
    <p><small>
       In random forest, The sample is generated randomly with each training data point having the equal probability of being sampled. 
       If N represents the size of training dataset and M is the number of random data points to be considered for training, 
       each point is randomly sampled with replacement.<br>
       In the training process, we create k models, where k is a predefined number and a hyperparameter that is easy to configure. 
       Each tree is constructed independently, and thus, the process can be implemented in parallel. 
       Eventually, we will have k-independent decision trees with possibly different structures, 
       and they might give different results for the same test item. <br>
       if k=4 and the class labels predicted by the four models are 1, 0, 1, and 1, 
       there are three votes for 1 and one vote for 0. Thus, the final class that is assigned is 1
    </small></p>
    <img src="images\2025063003.jpg" alt="2025063003" width="300">
</div>
</section>

<section>
<div class="discussion">
    <h2>Python Example</h2>
    <pre><code>
# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import (accuracy_score, confusion_matrix, 
                             roc_curve, auc, classification_report)
from sklearn.datasets import make_classification
# Set style for plots
plt.style.use('seaborn-v0_8')

# ---------------------------------------------
# 1. Generate Dataset (6200 rows, 8 features)
# ---------------------------------------------
X, y = make_classification(
    n_samples=6200, n_features=8, n_informative=6,n_redundant=2,
    n_clusters_per_class=1,n_classes=2,class_sep=1.0,
    flip_y=0.01,  # Add slight noise     
    random_state=42
)

# Create feature names
feature_names = [f'Feature_{i+1}' for i in range(8)]
df = pd.DataFrame(X, columns=feature_names)
df['Target'] = y

print("Dataset Shape:", df.shape)
print("\nTarget Distribution:")
print(df['Target'].value_counts())
print("\nFirst 5 rows:")
print(df.head())

# ---------------------------------------------
# 2. Train-Test Split
# ---------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nTraining samples: {X_train.shape[0]}")
print(f"Testing samples: {X_test.shape[0]}")

# ---------------------------------------------
# 3. Initialize and Train Models
# ---------------------------------------------
# Base estimator for bagging
base_tree = DecisionTreeClassifier(random_state=42)

# Bagging Classifier
bagging_model = BaggingClassifier(
    estimator=base_tree,
    n_estimators=100,
    max_samples=0.8,
    max_features=0.8,
    bootstrap=True,
    bootstrap_features=False,
    oob_score=True,
    random_state=42,
    n_jobs=-1
)

# Random Forest Classifier
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=12,
    min_samples_split=5,
    min_samples_leaf=2,
    max_features='sqrt',
    oob_score=True,
    random_state=42,
    n_jobs=-1
)

# Train models
print("\nTraining models...")
bagging_model.fit(X_train, y_train)
rf_model.fit(X_train, y_train)

# Predictions
y_pred_bagging = bagging_model.predict(X_test)
y_pred_rf = rf_model.predict(X_test)

# Prediction probabilities for ROC/AUC
y_prob_bagging = bagging_model.predict_proba(X_test)[:, 1]
y_prob_rf = rf_model.predict_proba(X_test)[:, 1]

# ---------------------------------------------
# 4. Model Evaluation
# ---------------------------------------------
def evaluate_model(y_true, y_pred, y_prob, model_name):
    accuracy = accuracy_score(y_true, y_pred)
    auc_score = auc(*roc_curve(y_true, y_prob)[:2])
    cm = confusion_matrix(y_true, y_pred)
    
    print(f"\n {model_name}")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"AUC Score: {auc_score:.4f}")
    
    if model_name == "Bagging":
        print(f"OOB Score: {bagging_model.oob_score_:.4f}")
    elif model_name == "Random Forest":
        print(f"OOB Score: {rf_model.oob_score_:.4f}")
    
    print("\n Classification Report:")
    print(classification_report(y_true, y_pred))
    
    return cm, auc_score

# Evaluate both models
cm_bagging, auc_bagging = evaluate_model(y_test, y_pred_bagging, y_prob_bagging, "Bagging")
cm_rf, auc_rf = evaluate_model(y_test, y_pred_rf, y_prob_rf, "Random Forest")

# ---------------------------------------------
# 5. Visualization
# ---------------------------------------------
fig, axes = plt.subplots(2, 2, figsize=(14, 12))

# Confusion Matrix - Bagging
sns.heatmap(cm_bagging, annot=True, fmt='d', cmap='Blues', ax=axes[0,0])
axes[0,0].set_title(f'Bagging Confusion Matrix\nAccuracy: {accuracy_score(y_test, y_pred_bagging):.4f}')
axes[0,0].set_ylabel('True Label')
axes[0,0].set_xlabel('Predicted Label')

# Confusion Matrix - Random Forest
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', ax=axes[0,1])
axes[0,1].set_title(f'Random Forest Confusion Matrix\nAccuracy: {accuracy_score(y_test, y_pred_rf):.4f}')
axes[0,1].set_ylabel('True Label')
axes[0,1].set_xlabel('Predicted Label')

# ROC Curves
fpr_bag, tpr_bag, _ = roc_curve(y_test, y_prob_bagging)
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)

axes[1,0].plot(fpr_bag, tpr_bag, label=f'Bagging (AUC = {auc_bagging:.4f})', color='blue', linewidth=2)
axes[1,0].plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.4f})', color='green', linewidth=2)
axes[1,0].plot([0, 1], [0, 1], 'k--', label='Random Guess')
axes[1,0].set_xlabel('False Positive Rate')
axes[1,0].set_ylabel('True Positive Rate')
axes[1,0].set_title('ROC Curves')
axes[1,0].legend()
axes[1,0].grid(True, alpha=0.3)

# Feature Importance (Random Forest)
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': rf_model.feature_importances_
}).sort_values('Importance', ascending=False)

sns.barplot(data=importance_df, x='Importance', y='Feature', ax=axes[1,1], palette='viridis')
axes[1,1].set_title('Random Forest: Feature Importance')

plt.tight_layout()
plt.show()

# ---------------------------------------------
# 6. Summary Table
# ---------------------------------------------
summary = pd.DataFrame({
    'Model': ['Bagging', 'Random Forest'],
    'Accuracy': [
        accuracy_score(y_test, y_pred_bagging),
        accuracy_score(y_test, y_pred_rf)
    ],
    'AUC Score': [auc_bagging, auc_rf],
    'OOB Score': [bagging_model.oob_score_, rf_model.oob_score_]
})

print("\nSummary Table:")
print(summary.round(4))
    </code></pre>
</div>
</section>

<section id="topic2">
<div class="summary">
    <h1>Boosting Algorithms</h1>
    <p><small>
    In boosting, the ensemble is created <mark>incrementally</mark> by training a new model 
    from a subset of the training data that considers a more proportion of data points that the previous models misclassified.
    </small></p>
    <h2>AdaBoost Algorithms</h2>
    <p><small>
       Initially, AdaBoost assigns each training tuple an equal weight of 1/d. 
       Generating k classifiers for the ensemble requires k rounds through the rest of the algorithm. 
       In round i, the tuples from D are sampled to form a training set, Di, of size d. 
       Sampling with replacement is used – the same tuple may be selected more than once. 
       Each tuple’s chance of being selected is based on its weight. 
    </small></p>
    <img src="images\2025063005.jpg" alt="2025063005" width="400">
    <p><small>
       The weights of the training tuples are then adjusted according to how they were classified. 
       If a tuple was incorrectly classified, its weight is increased. 
       If a tuple was correctly classified, its weight is decreased. 
       A tuple’s weight reflects how difficult it is to classify – the higher the weight, the more often it has been misclassified.
    </small></p> 
</div>
</section>


<section>
<div class="discussion">
    <h2>Python Example</h2>
    <pre><code>
# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import (accuracy_score, confusion_matrix,
                             roc_curve, auc, classification_report
)
from sklearn.datasets import make_classification
plt.style.use('seaborn-v0_8')


# ---------------------------------------------
# 1. Generate Dataset (6200 rows, 8 features)
# ---------------------------------------------
X, y = make_classification(
    n_samples=6200, n_features=8, n_informative=6,n_redundant=2,
    n_clusters_per_class=1,n_classes=2,class_sep=1.0,
    flip_y=0.01,  # Add slight noise     
    random_state=42
)

# Create feature names
feature_names = [f'Feature_{i+1}' for i in range(8)]
df = pd.DataFrame(X, columns=feature_names)
df['Target'] = y

print("Dataset Shape:", df.shape)
print("\nTarget Distribution:")
print(df['Target'].value_counts())
print("\nFirst 5 rows:")
print(df.head())

# ---------------------------------------------
# 2. Train-Test Split
# ---------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nTraining samples: {X_train.shape[0]}")
print(f"Testing samples: {X_test.shape[0]}")

# ---------------------------------------------
# 3. AdaBoost Model with Decision Stump
# ---------------------------------------------
# Base estimator: Decision stump (shallow tree)
base_classifier = DecisionTreeClassifier(max_depth=1, random_state=42)

# AdaBoost Classifier
ada_model = AdaBoostClassifier(
    estimator=base_classifier,
    n_estimators=100,
    learning_rate=1.0,
    algorithm='SAMME',  
    # Changed from 'SAMME.R' to 'SAMME' for compatibility
    random_state=42
)

# Train the model
print("\nTraining AdaBoost model...")
ada_model.fit(X_train, y_train)

# Predictions
y_pred = ada_model.predict(X_test)
y_pred_proba = ada_model.predict_proba(X_test)[:, 1]  # Probability for positive class

# ---------------------------------------------
# 4. Model Evaluation
# ---------------------------------------------
accuracy = accuracy_score(y_test, y_pred)
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
auc_score = auc(fpr, tpr)

print(f"\n AdaBoost Performance")
print(f"Accuracy: {accuracy:.4f}")
print(f"AUC Score: {auc_score:.4f}")
print(f"Number of Weak Learners: {ada_model.n_estimators}")

print("\n Classification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

# ---------------------------------------------
# 5. Visualization
# ---------------------------------------------
fig, axes = plt.subplots(2, 2, figsize=(14, 12))

# Confusion Matrix
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0])
axes[0, 0].set_title(f'AdaBoost Confusion Matrix\nAccuracy: {accuracy:.4f}')
axes[0, 0].set_ylabel('True Label')
axes[0, 0].set_xlabel('Predicted Label')

# ROC Curve
axes[0, 1].plot(fpr, tpr, label=f'AdaBoost (AUC = {auc_score:.4f})', color='darkorange', linewidth=2)
axes[0, 1].plot([0, 1], [0, 1], 'k--', label='Random Classifier')
axes[0, 1].set_xlabel('False Positive Rate')
axes[0, 1].set_ylabel('True Positive Rate')
axes[0, 1].set_title('ROC Curve - AdaBoost')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Feature Importance (Note: Aggregated from weak learners, may not be precise)
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': ada_model.feature_importances_
}).sort_values('Importance', ascending=False)

sns.barplot(data=importance_df, x='Importance', y='Feature', ax=axes[1, 0], hue='Feature', palette='viridis', legend=False)
axes[1, 0].set_title('AdaBoost: Feature Importance')

# Learning Curve: Error vs Number of Estimators (Using staged_predict)
errors = []
for y_pred_stage in ada_model.staged_predict(X_test):
    errors.append(1 - accuracy_score(y_test, y_pred_stage))

axes[1, 1].plot(range(1, len(errors) + 1), errors, label='Test Error', color='red')
axes[1, 1].set_xlabel('Number of Weak Learners')
axes[1, 1].set_ylabel('Error Rate')
axes[1, 1].set_title('AdaBoost: Error vs Number of Estimators')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# ---------------------------------------------
# 6. Compare with Other Models
# ---------------------------------------------
# Train other models
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
bagging_model = BaggingClassifier(n_estimators=100, random_state=42)

rf_model.fit(X_train, y_train)
bagging_model.fit(X_train, y_train)

# Model comparison
print("\n Model Comparison:")
print(f"{'Model':<15} {'Accuracy':<10} {'AUC':<10}")
print("-" * 35)

def calc_auc(y_true, y_prob):
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    return auc(fpr, tpr)

# AdaBoost
acc_ada = accuracy_score(y_test, y_pred)
auc_ada = calc_auc(y_test, y_pred_proba)
print(f"{'AdaBoost':<15} {acc_ada:<10.4f} {auc_ada:<10.4f}")

# Random Forest
y_pred_rf = rf_model.predict(X_test)
y_prob_rf = rf_model.predict_proba(X_test)[:, 1]
acc_rf = accuracy_score(y_test, y_pred_rf)
auc_rf = calc_auc(y_test, y_prob_rf)
print(f"{'Random Forest':<15} {acc_rf:<10.4f} {auc_rf:<10.4f}")

# Bagging
y_pred_bag = bagging_model.predict(X_test)
y_prob_bag = bagging_model.predict_proba(X_test)[:, 1]
acc_bag = accuracy_score(y_test, y_pred_bag)
auc_bag = calc_auc(y_test, y_prob_bag)
print(f"{'Bagging':<15} {acc_bag:<10.4f} {auc_bag:<10.4f}")

    </code></pre>
</div>
</section>

<section>
<div class="discussion">
    <h2>Another types of boosting algorithms</h2>
    <p><small>
       <ul>
        <li>Gradient boosting: The overall learner gradually improves on the observations where the residuals have been initially high.</li>
        <li>Extreme gradient boosting: Extreme gradient boosting of XGB is an advanced boosting algorithm. 
            It has become quite popular lately and has won many data science and ML competitions</li>
        <li>LightGBM (Light Gradient Boosting Machine) is a high-performance, distributed, and efficient gradient boosting framework developed by Microsoft. 
            It's designed for speed, low memory usage, and scalability on large datasets</li>    
       </ul> 
    </small></p>
</div>
</section>

<section >
<div class="summary">
    <h2>Python Example</h2>
    <pre><code>
# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import (AdaBoostClassifier, RandomForestClassifier,
                            BaggingClassifier, GradientBoostingClassifier
)
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import (accuracy_score, confusion_matrix,
                             roc_curve, auc, classification_report
)
from sklearn.datasets import make_classification
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
plt.style.use('seaborn-v0_8')


# ---------------------------------------------
# 1. Generate Dataset (6200 rows, 8 features)
# ---------------------------------------------
X, y = make_classification(
    n_samples=6200, n_features=8, n_informative=6,n_redundant=2,
    n_clusters_per_class=1,n_classes=2,class_sep=1.0,
    flip_y=0.01,  # Add slight noise     
    random_state=42
)

# Create feature names
feature_names = [f'Feature_{i+1}' for i in range(8)]
df = pd.DataFrame(X, columns=feature_names)
df['Target'] = y

print("Dataset Shape:", df.shape)
print("\nTarget Distribution:")
print(df['Target'].value_counts())
print("\nFirst 5 rows:")
print(df.head())

# ---------------------------------------------
# 2. Train-Test Split
# ---------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nTraining samples: {X_train.shape[0]}")
print(f"Testing samples: {X_test.shape[0]}")

# ---------------------------------------------
# 3. AdaBoost Model with Decision Stump
# ---------------------------------------------
# Base estimator: Decision stump (shallow tree)
base_classifier = DecisionTreeClassifier(max_depth=1, random_state=42)

# AdaBoost Classifier
ada_model = AdaBoostClassifier(
    estimator=base_classifier,
    n_estimators=100,
    learning_rate=1.0,
    algorithm='SAMME',  # Compatible with older scikit-learn versions
    random_state=42
)

# Train the model
print("\nTraining AdaBoost model...")
ada_model.fit(X_train, y_train)

# Predictions
y_pred = ada_model.predict(X_test)
y_pred_proba = ada_model.predict_proba(X_test)[:, 1]  # Probability for positive class

# ---------------------------------------------
# 4. Model Evaluation
# ---------------------------------------------
accuracy = accuracy_score(y_test, y_pred)
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
auc_score = auc(fpr, tpr)

print(f"\n AdaBoost Performance")
print(f"Accuracy: {accuracy:.4f}")
print(f"AUC Score: {auc_score:.4f}")
print(f"Number of Weak Learners: {ada_model.n_estimators}")

print("\n Classification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

# ---------------------------------------------
# 5. Visualization
# ---------------------------------------------
fig, axes = plt.subplots(2, 2, figsize=(14, 12))

# Confusion Matrix
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0])
axes[0, 0].set_title(f'AdaBoost Confusion Matrix\nAccuracy: {accuracy:.4f}')
axes[0, 0].set_ylabel('True Label')
axes[0, 0].set_xlabel('Predicted Label')

# ROC Curve
axes[0, 1].plot(fpr, tpr, label=f'AdaBoost (AUC = {auc_score:.4f})', color='darkorange', linewidth=2)
axes[0, 1].plot([0, 1], [0, 1], 'k--', label='Random Classifier')
axes[0, 1].set_xlabel('False Positive Rate')
axes[0, 1].set_ylabel('True Positive Rate')
axes[0, 1].set_title('ROC Curve - AdaBoost')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Feature Importance (Note: Aggregated from weak learners, may not be precise)
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': ada_model.feature_importances_
}).sort_values('Importance', ascending=False)

sns.barplot(data=importance_df, x='Importance', y='Feature', ax=axes[1, 0], hue='Feature', palette='viridis', legend=False)
axes[1, 0].set_title('AdaBoost: Feature Importance')

# Learning Curve: Error vs Number of Estimators (Using staged_predict)
errors = []
for y_pred_stage in ada_model.staged_predict(X_test):
    errors.append(1 - accuracy_score(y_test, y_pred_stage))

axes[1, 1].plot(range(1, len(errors) + 1), errors, label='Test Error', color='red')
axes[1, 1].set_xlabel('Number of Weak Learners')
axes[1, 1].set_ylabel('Error Rate')
axes[1, 1].set_title('AdaBoost: Error vs Number of Estimators')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# ---------------------------------------------
# 6. Compare with Other Models
# ---------------------------------------------
# Train other models
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
bagging_model = BaggingClassifier(n_estimators=100, random_state=42)
gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
xgb_model = XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')
lgb_model = LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)

# Fit all models
print("\nTraining additional models...")
rf_model.fit(X_train, y_train)
bagging_model.fit(X_train, y_train)
gb_model.fit(X_train, y_train)
xgb_model.fit(X_train, y_train)
lgb_model.fit(X_train, y_train)

# Model comparison
print("\n Model Comparison:")
print(f"{'Model':<25} {'Accuracy':<10} {'AUC':<10}")
print("-" * 45)

def calc_auc(y_true, y_prob):
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    return auc(fpr, tpr)

# AdaBoost
acc_ada = accuracy_score(y_test, y_pred)
auc_ada = calc_auc(y_test, y_pred_proba)
print(f"{'AdaBoost':<25} {acc_ada:<10.4f} {auc_ada:<10.4f}")

# Random Forest
y_pred_rf = rf_model.predict(X_test)
y_prob_rf = rf_model.predict_proba(X_test)[:, 1]
acc_rf = accuracy_score(y_test, y_pred_rf)
auc_rf = calc_auc(y_test, y_prob_rf)
print(f"{'Random Forest':<25} {acc_rf:<10.4f} {auc_rf:<10.4f}")

# Bagging
y_pred_bag = bagging_model.predict(X_test)
y_prob_bag = bagging_model.predict_proba(X_test)[:, 1]
acc_bag = accuracy_score(y_test, y_pred_bag)
auc_bag = calc_auc(y_test, y_prob_bag)
print(f"{'Bagging':<25} {acc_bag:<10.4f} {auc_bag:<10.4f}")

# Gradient Boosting
y_pred_gb = gb_model.predict(X_test)
y_prob_gb = gb_model.predict_proba(X_test)[:, 1]
acc_gb = accuracy_score(y_test, y_pred_gb)
auc_gb = calc_auc(y_test, y_prob_gb)
print(f"{'Gradient Boosting':<25} {acc_gb:<10.4f} {auc_gb:<10.4f}")

# XGBoost
y_pred_xgb = xgb_model.predict(X_test)
y_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]
acc_xgb = accuracy_score(y_test, y_pred_xgb)
auc_xgb = calc_auc(y_test, y_prob_xgb)
print(f"{'XGBoost':<25} {acc_xgb:<10.4f} {auc_xgb:<10.4f}")

# LightGBM
y_pred_lgb = lgb_model.predict(X_test)
y_prob_lgb = lgb_model.predict_proba(X_test)[:, 1]
acc_lgb = accuracy_score(y_test, y_pred_lgb)
auc_lgb = calc_auc(y_test, y_prob_lgb)
print(f"{'LightGBM':<25} {acc_lgb:<10.4f} {auc_lgb:<10.4f}")
    </code></pre>
</div>
</section>

<section id="topic3">
<div class="discussion">
    <h1>Stacking Algorithms</h1>
    <p><small>
        Stacking, or stacked generalization, is another ensemble learning technique 
        that combines the predictions from <mark>multiple machine learning models</mark> 
        by assigning the weights on individual constituent classifiers. Stacking (Stacked Generalization) is an advanced ensemble learning technique 
        that combines multiple base models (called `level-0 models` or `base learners`) 
        using a <mark>meta-model (level-1 model)</mark> to learn how to best combine their predictions.
    </small></p>
</div>
</section>
  


<section >
<div class="summary">
    <h2>Python Example</h2>
    <pre><code>
# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import (AdaBoostClassifier, RandomForestClassifier,
                            BaggingClassifier,GradientBoostingClassifier,
                              StackingClassifier
)
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import (accuracy_score, confusion_matrix,
                             roc_curve, auc, classification_report
)
from sklearn.datasets import make_classification
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
plt.style.use('seaborn-v0_8')


# ---------------------------------------------
# 1. Generate Dataset (6200 rows, 8 features)
# ---------------------------------------------
X, y = make_classification(
    n_samples=6200, n_features=8, n_informative=6,n_redundant=2,
    n_clusters_per_class=1,n_classes=2,class_sep=1.0,
    flip_y=0.01,  # Add slight noise     
    random_state=42
)

# Create feature names
feature_names = [f'Feature_{i+1}' for i in range(8)]
df = pd.DataFrame(X, columns=feature_names)
df['Target'] = y

print("Dataset Shape:", df.shape)
print("\nTarget Distribution:")
print(df['Target'].value_counts())
print("\nFirst 5 rows:")
print(df.head())

# ---------------------------------------------
# 2. Train-Test Split
# ---------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nTraining samples: {X_train.shape[0]}")
print(f"Testing samples: {X_test.shape[0]}")

# ---------------------------------------------
# 3. AdaBoost Model with Decision Stump
# ---------------------------------------------
# Base estimator: Decision stump (shallow tree)
base_classifier = DecisionTreeClassifier(max_depth=1, random_state=42)

# AdaBoost Classifier
ada_model = AdaBoostClassifier(
    estimator=base_classifier,
    n_estimators=100,
    learning_rate=1.0,
    algorithm='SAMME',  # Compatible with older scikit-learn versions
    random_state=42
)

# Train the model
print("\nTraining AdaBoost model...")
ada_model.fit(X_train, y_train)

# Predictions
y_pred = ada_model.predict(X_test)
y_pred_proba = ada_model.predict_proba(X_test)[:, 1]  # Probability for positive class

# ---------------------------------------------
# 4. Model Evaluation
# ---------------------------------------------
accuracy = accuracy_score(y_test, y_pred)
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
auc_score = auc(fpr, tpr)

print(f"\n AdaBoost Performance")
print(f"Accuracy: {accuracy:.4f}")
print(f"AUC Score: {auc_score:.4f}")
print(f"Number of Weak Learners: {ada_model.n_estimators}")

print("\n Classification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

# ---------------------------------------------
# 5. Visualization
# ---------------------------------------------
fig, axes = plt.subplots(2, 2, figsize=(14, 12))

# Confusion Matrix
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0])
axes[0, 0].set_title(f'AdaBoost Confusion Matrix\nAccuracy: {accuracy:.4f}')
axes[0, 0].set_ylabel('True Label')
axes[0, 0].set_xlabel('Predicted Label')

# ROC Curve
axes[0, 1].plot(fpr, tpr, label=f'AdaBoost (AUC = {auc_score:.4f})', color='darkorange', linewidth=2)
axes[0, 1].plot([0, 1], [0, 1], 'k--', label='Random Classifier')
axes[0, 1].set_xlabel('False Positive Rate')
axes[0, 1].set_ylabel('True Positive Rate')
axes[0, 1].set_title('ROC Curve - AdaBoost')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Feature Importance (Note: Aggregated from weak learners, may not be precise)
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': ada_model.feature_importances_
}).sort_values('Importance', ascending=False)

sns.barplot(data=importance_df, x='Importance', y='Feature', ax=axes[1, 0], hue='Feature', palette='viridis', legend=False)
axes[1, 0].set_title('AdaBoost: Feature Importance')

# Learning Curve: Error vs Number of Estimators (Using staged_predict)
errors = []
for y_pred_stage in ada_model.staged_predict(X_test):
    errors.append(1 - accuracy_score(y_test, y_pred_stage))

axes[1, 1].plot(range(1, len(errors) + 1), errors, label='Test Error', color='red')
axes[1, 1].set_xlabel('Number of Weak Learners')
axes[1, 1].set_ylabel('Error Rate')
axes[1, 1].set_title('AdaBoost: Error vs Number of Estimators')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# ---------------------------------------------
# 6. Compare with Other Models
# ---------------------------------------------
# Define base models for stacking and individual evaluation
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
bagging_model = BaggingClassifier(n_estimators=100, random_state=42)
gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
xgb_model = XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')
lgb_model = LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)

# Stacking Ensemble
estimators = [
    ('ada', ada_model),
    ('rf', rf_model),
    ('bag', bagging_model),
    ('gb', gb_model),
    ('xgb', xgb_model),
    ('lgb', lgb_model)
]
stacking_model = StackingClassifier(
    estimators=estimators,
    final_estimator=LogisticRegression(random_state=42),
    cv=5,
    n_jobs=-1  # Use all available CPU cores
)

# Train all models
print("\nTraining additional models...")
rf_model.fit(X_train, y_train)
bagging_model.fit(X_train, y_train)
gb_model.fit(X_train, y_train)
xgb_model.fit(X_train, y_train)
lgb_model.fit(X_train, y_train)
print("Training Stacking Ensemble...")
stacking_model.fit(X_train, y_train)

# Model comparison
print("\n Model Comparison:")
print(f"{'Model':<25} {'Accuracy':<10} {'AUC':<10}")
print("-" * 45)

def calc_auc(y_true, y_prob):
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    return auc(fpr, tpr)

# AdaBoost
acc_ada = accuracy_score(y_test, y_pred)
auc_ada = calc_auc(y_test, y_pred_proba)
print(f"{'AdaBoost':<25} {acc_ada:<10.4f} {auc_ada:<10.4f}")

# Random Forest
y_pred_rf = rf_model.predict(X_test)
y_prob_rf = rf_model.predict_proba(X_test)[:, 1]
acc_rf = accuracy_score(y_test, y_pred_rf)
auc_rf = calc_auc(y_test, y_prob_rf)
print(f"{'Random Forest':<25} {acc_rf:<10.4f} {auc_rf:<10.4f}")

# Bagging
y_pred_bag = bagging_model.predict(X_test)
y_prob_bag = bagging_model.predict_proba(X_test)[:, 1]
acc_bag = accuracy_score(y_test, y_pred_bag)
auc_bag = calc_auc(y_test, y_prob_bag)
print(f"{'Bagging':<25} {acc_bag:<10.4f} {auc_bag:<10.4f}")

# Gradient Boosting
y_pred_gb = gb_model.predict(X_test)
y_prob_gb = gb_model.predict_proba(X_test)[:, 1]
acc_gb = accuracy_score(y_test, y_pred_gb)
auc_gb = calc_auc(y_test, y_prob_gb)
print(f"{'Gradient Boosting':<25} {acc_gb:<10.4f} {auc_gb:<10.4f}")

# XGBoost
y_pred_xgb = xgb_model.predict(X_test)
y_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]
acc_xgb = accuracy_score(y_test, y_pred_xgb)
auc_xgb = calc_auc(y_test, y_prob_xgb)
print(f"{'XGBoost':<25} {acc_xgb:<10.4f} {auc_xgb:<10.4f}")

# LightGBM
y_pred_lgb = lgb_model.predict(X_test)
y_prob_lgb = lgb_model.predict_proba(X_test)[:, 1]
acc_lgb = accuracy_score(y_test, y_pred_lgb)
auc_lgb = calc_auc(y_test, y_prob_lgb)
print(f"{'LightGBM':<25} {acc_lgb:<10.4f} {auc_lgb:<10.4f}")

# Stacking Ensemble
y_pred_stack = stacking_model.predict(X_test)
y_prob_stack = stacking_model.predict_proba(X_test)[:, 1]
acc_stack = accuracy_score(y_test, y_pred_stack)
auc_stack = calc_auc(y_test, y_prob_stack)
print(f"{'Stacking Ensemble':<25} {acc_stack:<10.4f} {auc_stack:<10.4f}")
    </code></pre>
</div>
</section>






</body>
</html>