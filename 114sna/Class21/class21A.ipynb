{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1. Generate synthetic social network (100 users, 4 topics)\n",
    "# --------------------------------------------------------------\n",
    "n_users = 100\n",
    "n_topics = 4\n",
    "users_per_topic = n_users // n_topics\n",
    "\n",
    "topic_names = [\"Sports\", \"Politics\", \"AI_Research\", \"Gaming\"]\n",
    "true_labels = [i // users_per_topic for i in range(n_users)]\n",
    "\n",
    "p_within = 0.25\n",
    "p_between = 0.02\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(n_users))\n",
    "\n",
    "for i in range(n_users):\n",
    "    for j in range(i+1, n_users):\n",
    "        if true_labels[i] == true_labels[j]:\n",
    "            if random.random() < p_within:\n",
    "                G.add_edge(i, j)\n",
    "        else:\n",
    "            if random.random() < p_between:\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "print(f\"Graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2. Compute ALL centrality measures\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# 1. Degree Centrality\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# 2. Betweenness Centrality (approximated for speed)\n",
    "betweenness_centrality = nx.betweenness_centrality(G, k=100, seed=42)\n",
    "\n",
    "# 3. Closeness Centrality\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "\n",
    "# 4. Eigenvector Centrality\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000, tol=1e-6)\n",
    "\n",
    "# 5. PageRank\n",
    "pagerank = nx.pagerank(G, alpha=0.85)\n",
    "\n",
    "# 6. NEW: Katz Centrality\n",
    "# Choose Î± < 1/Î»_max where Î»_max is the largest eigenvalue of adjacency matrix\n",
    "try:\n",
    "    # Safest: use NetworkX built-in (automatically chooses Î±)\n",
    "    katz_centrality = nx.katz_centrality(G, alpha=0.1, beta=1.0, max_iter=1000, tol=1e-6)\n",
    "except:\n",
    "    # Fallback: conservative Î±\n",
    "    katz_centrality = nx.katz_centrality(G, alpha=0.05, beta=1.0)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3. Get top 5 influencers for each measure\n",
    "# --------------------------------------------------------------\n",
    "def get_top_kols(centrality_dict, k=5):\n",
    "    return sorted(centrality_dict.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "top_katz = get_top_kols(katz_centrality)\n",
    "\n",
    "centralities = {\n",
    "    \"Degree\": get_top_kols(degree_centrality),\n",
    "    \"Betweenness\": get_top_kols(betweenness_centrality),\n",
    "    \"Closeness\": get_top_kols(closeness_centrality),\n",
    "    \"Eigenvector\": get_top_kols(eigenvector_centrality),\n",
    "    \"PageRank\": get_top_kols(pagerank),\n",
    "    \"Katz\": top_katz\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4. Print results with topic labels\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 5 INFLUENCERS (KOLs) BY CENTRALITY MEASURE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name, tops in centralities.items():\n",
    "    print(f\"\\n{name:12} Centrality â†’ Top 5 Users:\")\n",
    "    for rank, (user, score) in enumerate(tops, 1):\n",
    "        topic = topic_names[true_labels[user]]\n",
    "        print(f\"  #{rank} User {user:2d} ({topic:12}) â†’ Score: {score:.4f}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5. Visualize: Node size by Katz Centrality\n",
    "# --------------------------------------------------------------\n",
    "plt.figure(figsize=(12, 9))\n",
    "pos = nx.spring_layout(G, k=0.18, iterations=60, seed=42)\n",
    "\n",
    "# Node sizes scaled by Katz centrality\n",
    "katz_values = [katz_centrality[node] for node in G.nodes()]\n",
    "node_sizes = [2000 * v + 100 for v in katz_values]  # scale up\n",
    "\n",
    "# Color by true topic\n",
    "node_colors = true_labels\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.15, width=0.5)\n",
    "scatter = nx.draw_networkx_nodes(\n",
    "    G, pos,\n",
    "    node_size=node_sizes,\n",
    "    node_color=node_colors,\n",
    "    cmap=plt.cm.tab10,\n",
    "    alpha=0.9\n",
    ")\n",
    "\n",
    "# Highlight top 3 Katz influencers with red border\n",
    "top3_katz_users = [u for u, _ in top_katz[:3]]\n",
    "nx.draw_networkx_nodes(\n",
    "    G, pos,\n",
    "    nodelist=top3_katz_users,\n",
    "    node_size=800,\n",
    "    node_color=\"red\",\n",
    "    edgecolors=\"black\",\n",
    "    linewidths=3,\n",
    "    label=\"Top 3 Katz KOLs\"\n",
    ")\n",
    "\n",
    "plt.title(\"100-User Social Network\\nNode Size = Katz Centrality | Red Border = Top 3 KOLs\", \n",
    "          fontsize=14, pad=20)\n",
    "plt.axis(\"off\")\n",
    "plt.legend(scatterpoints=1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 6. Bonus: Correlation between Katz and other measures\n",
    "# --------------------------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Degree': degree_centrality,\n",
    "    'Betweenness': betweenness_centrality,\n",
    "    'Closeness': closeness_centrality,\n",
    "    'Eigenvector': eigenvector_centrality,\n",
    "    'PageRank': pagerank,\n",
    "    'Katz': katz_centrality\n",
    "})\n",
    "\n",
    "print(\"\\nCorrelation with Katz Centrality:\")\n",
    "print(df.corr()['Katz'].round(4).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ca3498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ========================================\n",
    "# 1. Create a polarized network with 100 users\n",
    "# ========================================\n",
    "n_left = 50   # Left community\n",
    "n_right = 50  # Right community\n",
    "n = n_left + n_right\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with ideology attribute\n",
    "for i in range(n_left):\n",
    "    G.add_node(f\"L{i}\", ideology=\"Left\")\n",
    "for i in range(n_right):\n",
    "    G.add_node(f\"R{i}\", ideology=\"Right\")\n",
    "\n",
    "# ========================================\n",
    "# 2. Add dense connections WITHIN each side (homophily)\n",
    "# ========================================\n",
    "# Left community: high connection probability\n",
    "for i in range(n_left):\n",
    "    for j in range(i+1, n_left):\n",
    "        if random.random() < 0.25:  # dense\n",
    "            G.add_edge(f\"L{i}\", f\"L{j}\")\n",
    "\n",
    "# Right community: high connection probability\n",
    "for i in range(n_right):\n",
    "    for j in range(i+1, n_right):\n",
    "        if random.random() < 0.25:\n",
    "            G.add_edge(f\"R{i}\", f\"R{j}\")\n",
    "\n",
    "# ========================================\n",
    "# 3. Add ONLY 4 cross-ideology bridges (the interesting part!)\n",
    "# ========================================\n",
    "bridges = [\n",
    "    (\"L5\",  \"R8\"),   # a journalist both sides follow\n",
    "    (\"L12\", \"R3\"),   # a moderate politician\n",
    "    (\"L23\", \"R19\"),  # local news outlet\n",
    "    (\"L41\", \"R33\")   # satire account\n",
    "]\n",
    "\n",
    "for a, b in bridges:\n",
    "    G.add_edge(a, b)\n",
    "\n",
    "# ========================================\n",
    "# 4. Compute betweenness centrality\n",
    "# ========================================\n",
    "betweenness = nx.betweenness_centrality(G)\n",
    "\n",
    "# Convert to sorted list\n",
    "sorted_betweenness = sorted(betweenness.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 15 nodes by betweenness centrality:\")\n",
    "print(\"-\" * 50)\n",
    "for node, bc in sorted_betweenness[:15]:\n",
    "    ideology = G.nodes[node]['ideology']\n",
    "    is_bridge = \"BRIDGE\" if any((node == a or node == b) for a, b in bridges) else \"\"\n",
    "    print(f\"{node:4} | Betweenness: {bc:6.4f} | {ideology:5} {is_bridge}\")\n",
    "\n",
    "# ========================================\n",
    "# 5. Visualize the network\n",
    "# ========================================\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# Color by ideology\n",
    "node_colors = ['#ff4444' if G.nodes[n]['ideology'] == 'Left' else '#4444ff' for n in G.nodes()]\n",
    "\n",
    "# Make bridge nodes larger and yellow\n",
    "node_sizes = []\n",
    "for node in G.nodes():\n",
    "    if any((node == a or node == b) for a, b in bridges):\n",
    "        node_sizes.append(400)\n",
    "    else:\n",
    "        node_sizes.append(80)\n",
    "\n",
    "nx.draw(G, pos,\n",
    "        node_color=node_colors,\n",
    "        node_size=node_sizes,\n",
    "        with_labels=False,\n",
    "        edge_color='gray',\n",
    "        alpha=0.7)\n",
    "\n",
    "# Highlight bridges in yellow\n",
    "bridge_nodes = set()\n",
    "for a, b in bridges:\n",
    "    bridge_nodes.add(a)\n",
    "    bridge_nodes.add(b)\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos,\n",
    "                       nodelist=bridge_nodes,\n",
    "                       node_color='yellow',\n",
    "                       node_size=500,\n",
    "                       edgecolors='black',\n",
    "                       linewidths=2)\n",
    "\n",
    "plt.title(\"Polarized Network with 4 Cross-Ideology Bridges (yellow nodes)\\n\"\n",
    "          \"Betweenness centrality perfectly detects them!\", fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4658de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Simulate Customer Interaction Data\n",
    "# ----------------------------\n",
    "# Example: platform where users collaborate (message, share files, mention)\n",
    "# Format: (user, interacts_with)\n",
    "interactions = [\n",
    "    (\"user1\", \"user2\"),\n",
    "    (\"user1\", \"user3\"),\n",
    "    (\"user2\", \"user3\"),\n",
    "    (\"user4\", \"user5\"),\n",
    "    (\"user5\", \"user4\"),\n",
    "    # Isolated or near-isolated users (churn risk)\n",
    "    (\"user6\", \"user7\"),  # only one weak link\n",
    "    (\"user8\", None),     # completely isolated\n",
    "    (\"user9\", None),\n",
    "    (\"user10\", \"user11\"),\n",
    "    (\"user11\", \"user10\"),\n",
    "    (\"user12\", None),    # silent user\n",
    "]\n",
    "\n",
    "# Build an undirected graph of user interactions\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add all users\n",
    "all_users = set()\n",
    "for u, v in interactions: # å–å‡ºsenter, receiver\n",
    "    all_users.add(u)\n",
    "    if v is not None:\n",
    "        all_users.add(v)\n",
    "\n",
    "G.add_nodes_from(all_users)\n",
    "\n",
    "# Add edges where interaction exists\n",
    "for u, v in interactions:\n",
    "    if v is not None:\n",
    "        G.add_edge(u, v)\n",
    "\n",
    "print(f\"Total users: {G.number_of_nodes()}\")\n",
    "print(f\"Connected users: {len([n for n in G.nodes() if G.degree(n) > 0])}\")\n",
    "print(f\"Isolated users: {len([n for n in G.nodes() if G.degree(n) == 0])}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Identify At-Risk (Churn-Prone) Customers\n",
    "# ----------------------------\n",
    "churn_risk = []\n",
    "\n",
    "for user in G.nodes():\n",
    "    degree = G.degree(user)\n",
    "    # Ego network = user + direct neighbors\n",
    "    ego = nx.ego_graph(G, user, radius=1)\n",
    "    ego_size = ego.number_of_nodes()  # 1 = isolated\n",
    "    \n",
    "    # Optional: clustering coefficient (how connected are their friends?)\n",
    "    # Not defined for degree < 2\n",
    "    clustering = nx.clustering(G, user) if degree >= 2 else 0.0\n",
    "    \n",
    "    # Heuristic for churn risk:\n",
    "    # - Degree == 0 â†’ completely isolated\n",
    "    # - Degree == 1 and ego_size == 2 â†’ only one weak tie\n",
    "    if degree == 0 or (degree == 1 and ego_size == 2):\n",
    "        churn_risk.append({\n",
    "            \"user\": user,\n",
    "            \"degree\": degree,\n",
    "            \"ego_size\": ego_size,\n",
    "            \"clustering\": clustering\n",
    "        })\n",
    "\n",
    "print(f\"\\n {len(churn_risk)} users flagged for high churn risk:\")\n",
    "for r in churn_risk:\n",
    "    print(f\"  {r['user']}: degree={r['degree']}, ego_size={r['ego_size']}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Prioritize for Retention Campaigns\n",
    "# ----------------------------\n",
    "# Example: Offer onboarding help, feature tutorial, or referral bonus\n",
    "retention_actions = {\n",
    "    \"degree=0\": \"Send re-engagement email + product walkthrough\",\n",
    "    \"degree=1\": \"Suggest connections or team members to invite\"\n",
    "}\n",
    "\n",
    "print(\"\\n Suggested retention actions:\")\n",
    "for r in churn_risk:\n",
    "    if r[\"degree\"] == 0:\n",
    "        action = retention_actions[\"degree=0\"]\n",
    "    else:\n",
    "        action = retention_actions[\"degree=1\"]\n",
    "    print(f\"  {r['user']} â†’ {action}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Visualize Network (Highlight At-Risk Users)\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(12, 8))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# Color nodes: green = connected, red = at-risk\n",
    "node_colors = []\n",
    "node_sizes = []\n",
    "for node in G.nodes():\n",
    "    if node in [r[\"user\"] for r in churn_risk]:\n",
    "        node_colors.append(\"red\")\n",
    "        node_sizes.append(600)\n",
    "    else:\n",
    "        node_colors.append(\"lightgreen\")\n",
    "        node_sizes.append(400)\n",
    "\n",
    "nx.draw(\n",
    "    G, pos,\n",
    "    node_color=node_colors,\n",
    "    node_size=node_sizes,\n",
    "    with_labels=True,\n",
    "    font_size=10,\n",
    "    edge_color=\"gray\"\n",
    ")\n",
    "\n",
    "plt.title(\"Customer Interaction Graph\\n Red = High Churn Risk (Isolated)\")\n",
    "plt.tight_layout()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc8ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Simulate a Referral/Interaction Network\n",
    "# ----------------------------\n",
    "# Format: (referrer, referred) â€” or (user1, user2) for mutual interaction\n",
    "edges = [\n",
    "    # Community A: Tech enthusiasts\n",
    "    (\"Alice\", \"Bob\"),\n",
    "    (\"Bob\", \"Charlie\"),\n",
    "    (\"Alice\", \"Charlie\"),\n",
    "    (\"Charlie\", \"Diana\"),\n",
    "    \n",
    "    # Community B: Fitness group\n",
    "    (\"Eve\", \"Frank\"),\n",
    "    (\"Frank\", \"Grace\"),\n",
    "    (\"Eve\", \"Grace\"),\n",
    "    \n",
    "    # Community C: Sustainability advocates\n",
    "    (\"Helen\", \"Ivy\"),\n",
    "    (\"Ivy\", \"Jack\"),\n",
    "    (\"Helen\", \"Jack\"),\n",
    "    \n",
    "    #  BRIDGE NODES (potential influencers)\n",
    "    (\"Diana\", \"Eve\"),   # connects Tech â†” Fitness\n",
    "    (\"Grace\", \"Helen\"), # connects Fitness â†” Sustainability\n",
    "    (\"Jack\", \"Alice\"),  # connects Sustainability â†” Tech â†’ forms a cycle\n",
    "]\n",
    "\n",
    "# Build an undirected graph (referrals are mutual in influence)\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges) # edge list\n",
    "\n",
    "print(f\"Network: {G.number_of_nodes()} users, {G.number_of_edges()} connections\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Compute Betweenness Centrality\n",
    "# ----------------------------\n",
    "betweenness = nx.betweenness_centrality(G)\n",
    "\n",
    "# Sort by betweenness (descending)\n",
    "influencers = sorted(betweenness.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\n Top Influencers by Betweenness Centrality:\")\n",
    "print(\"User\\t\\tBetweenness\\tRole\")\n",
    "print(\"-\" * 45)\n",
    "for user, score in influencers[:5]:\n",
    "    role = \"Bridge\" if score > 0.2 else \"Local\"\n",
    "    print(f\"{user:<12}\\t{score:.3f}\\t\\t{role}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Why Betweenness > Degree?\n",
    "# ----------------------------\n",
    "degree = dict(G.degree())\n",
    "print(\"\\n Degree vs. Betweenness (Top 5 by degree):\")\n",
    "print(\"User\\tDegree\\tBetweenness\")\n",
    "print(\"-\" * 30)\n",
    "for user in sorted(degree, key=degree.get, reverse=True)[:5]:\n",
    "    print(f\"{user:<12}\\t{degree[user]}\\t{betweenness[user]:.3f}\")\n",
    "\n",
    "# â†’ Notice: high-degree users may have LOW betweenness!\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Visualize: Highlight Bridge Influencers\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Get the current axes\n",
    "ax = plt.gca()\n",
    "\n",
    "# Layout\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# Color nodes by betweenness (red = high)\n",
    "node_colors = [betweenness[node] for node in G.nodes()]\n",
    "node_sizes = [3000 * betweenness[node] + 300 for node in G.nodes()]\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw(\n",
    "    G, pos,\n",
    "    node_color=node_colors,\n",
    "    cmap=plt.cm.plasma,\n",
    "    node_size=node_sizes,\n",
    "    with_labels=True,\n",
    "    font_size=10,\n",
    "    edge_color=\"gray\",\n",
    "    width=1.5,\n",
    "    ax=ax  # Explicitly pass ax\n",
    ")\n",
    "\n",
    "# Add colorbar using the same axes\n",
    "sm = plt.cm.ScalarMappable(\n",
    "    cmap=plt.cm.plasma,\n",
    "    norm=plt.Normalize(vmin=min(node_colors), vmax=max(node_colors))\n",
    ")\n",
    "sm.set_array([])  # Required for older matplotlib versions\n",
    "plt.colorbar(sm, ax=ax, label=\"Betweenness Centrality\")  # <-- pass ax here\n",
    "\n",
    "plt.title(\"Referral Network: Node Size & Color = Betweenness Centrality\\n Red/Large = Key Influencers (Bridge Communities)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Marketing Action: Target Bridge Influencers\n",
    "# ----------------------------\n",
    "top_influencer = influencers[0][0]\n",
    "print(f\"\\n Recommendation: Partner with '{top_influencer}' for campaign.\")\n",
    "print(\"Why? They connect multiple communitiesâ€”maximizing spread and diversity of reach.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Simulate Stock Returns\n",
    "# ----------------------------\n",
    "np.random.seed(42)\n",
    "n_assets = 10\n",
    "n_days = 250\n",
    "\n",
    "# Generate a realistic (positive semi-definite) covariance matrix\n",
    "cov_matrix = make_spd_matrix(n_assets, random_state=42)\n",
    "# Simulate daily returns from multivariate normal\n",
    "returns = np.random.multivariate_normal(mean=np.zeros(n_assets), cov=cov_matrix, size=n_days)\n",
    "\n",
    "# Create a DataFrame with asset labels\n",
    "assets = [f\"Asset_{i}\" for i in range(1, n_assets + 1)]\n",
    "returns_df = pd.DataFrame(returns, columns=assets)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Compute Correlation Matrix\n",
    "# ----------------------------\n",
    "corr = returns_df.corr()\n",
    "print(\"Correlation matrix (top-left 5x5):\")\n",
    "print(corr.iloc[:5, :5].round(2))\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Build Correlation Network\n",
    "# ----------------------------\n",
    "# Convert correlation to distance: d = sqrt(0.5 * (1 - corr))\n",
    "dist_matrix = np.sqrt(0.5 * (1 - corr))\n",
    "\n",
    "# Create a complete graph with distance as edge weight\n",
    "G = nx.Graph()\n",
    "for i in range(n_assets):\n",
    "    for j in range(i + 1, n_assets):\n",
    "        asset_i = assets[i]\n",
    "        asset_j = assets[j]\n",
    "        distance = dist_matrix.iloc[i, j]\n",
    "        G.add_edge(asset_i, asset_j, weight=distance)\n",
    "\n",
    "        # ----------------------------\n",
    "# 4. Extract Minimum Spanning Tree (MST)\n",
    "# ----------------------------\n",
    "mst = nx.minimum_spanning_tree(G, weight='weight')\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Analyze Risk: Centrality in MST\n",
    "# ----------------------------\n",
    "# In MST, high degree or betweenness = systemic risk hub\n",
    "degree_centrality = nx.degree_centrality(mst)\n",
    "betweenness = nx.betweenness_centrality(mst)\n",
    "\n",
    "# Rank assets by betweenness (most influential in risk propagation)\n",
    "risk_ranking = sorted(betweenness.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nTop risk-conduit assets (by betweenness centrality in MST):\")\n",
    "for asset, score in risk_ranking[:3]:\n",
    "    print(f\"  {asset}: {score:.3f}\")\n",
    "    \n",
    "# ----------------------------\n",
    "# 6. Visualize MST\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "pos = nx.spring_layout(mst, seed=42)\n",
    "\n",
    "# Node size proportional to betweenness\n",
    "node_sizes = [5000 * betweenness[node] + 300 for node in mst.nodes()]\n",
    "\n",
    "nx.draw(mst, pos,\n",
    "        with_labels=True,\n",
    "        node_size=node_sizes,\n",
    "        node_color='lightgreen',\n",
    "        font_size=9,\n",
    "        edge_color='gray')\n",
    "\n",
    "plt.title(\"Portfolio Risk Network: Minimum Spanning Tree\\n(Node size âˆ risk influence)\")\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16692dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Build a Denser Network with 30 Firms\n",
    "# ----------------------------\n",
    "np.random.seed(42)\n",
    "n_firms = 30\n",
    "firm_names = [f\"Firm_{i}\" for i in range(n_firms)]\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(firm_names)\n",
    "\n",
    "# Create a more interconnected network: each firm supplies 2â€“4 others on average\n",
    "for i in range(n_firms):\n",
    "    num_customers = np.random.randint(2, 5)  # more connections\n",
    "    candidates = [f for f in firm_names if f != firm_names[i]]\n",
    "    customers = np.random.choice(candidates, size=min(num_customers, len(candidates)), replace=False)\n",
    "    for c in customers:\n",
    "        G.add_edge(firm_names[i], c)\n",
    "\n",
    "# Assign capacities\n",
    "firm_data = {firm: {'capacity': np.random.uniform(100, 600)} for firm in firm_names}\n",
    "\n",
    "# Assign supply shares (normalize per customer)\n",
    "for customer in firm_names:\n",
    "    suppliers = list(G.predecessors(customer))\n",
    "    if suppliers:\n",
    "        weights = np.random.dirichlet(np.ones(len(suppliers)) * 2)  # smoother distribution\n",
    "        for i, supplier in enumerate(suppliers):\n",
    "            G[supplier][customer]['supply_share'] = weights[i]\n",
    "\n",
    "print(f\"Network: {G.number_of_nodes()} firms, {G.number_of_edges()} supply links\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Compute Centrality Metrics\n",
    "# ----------------------------\n",
    "pagerank = nx.pagerank(G, weight='supply_share', alpha=0.85)\n",
    "G_undir = G.to_undirected()\n",
    "betweenness = nx.betweenness_centrality(G_undir, weight='supply_share')\n",
    "\n",
    "# Find firm with highest combined centrality\n",
    "combined_score = {f: pagerank[f] + betweenness[f] for f in firm_names}\n",
    "disrupted_firm = max(combined_score, key=combined_score.get)\n",
    "\n",
    "print(f\"\\nDisrupting: {disrupted_firm}\")\n",
    "print(f\"  PageRank: {pagerank[disrupted_firm]:.4f}\")\n",
    "print(f\"  Betweenness: {betweenness[disrupted_firm]:.4f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Simulate Disruption (Lower Threshold = More Cascade)\n",
    "# ----------------------------\n",
    "def simulate_disruption_cascade(G, firm_data, disrupted_firm, threshold=0.5, max_tiers=4):\n",
    "    status = {f: 'operational' for f in firm_names}\n",
    "    status[disrupted_firm] = 'disrupted'\n",
    "    affected_by_tier = {0: {disrupted_firm}}\n",
    "    newly_disrupted = {disrupted_firm}\n",
    "\n",
    "    for tier in range(1, max_tiers + 1):\n",
    "        next_disrupted = set()\n",
    "        for firm in newly_disrupted:\n",
    "            for customer in G.successors(firm):\n",
    "                if status[customer] != 'operational':\n",
    "                    continue\n",
    "                total_loss = sum(\n",
    "                    G[sup][customer].get('supply_share', 0)\n",
    "                    for sup in G.predecessors(customer)\n",
    "                    if status[sup] == 'disrupted'\n",
    "                )\n",
    "                if total_loss >= threshold:  # lowered from 0.7 â†’ 0.5\n",
    "                    status[customer] = 'disrupted'\n",
    "                    next_disrupted.add(customer)\n",
    "        if not next_disrupted:\n",
    "            break\n",
    "        affected_by_tier[tier] = next_disrupted\n",
    "        newly_disrupted = next_disrupted\n",
    "\n",
    "    total_output_loss = sum(firm_data[f]['capacity'] for f in firm_names if status[f] == 'disrupted')\n",
    "    default_count = sum(1 for s in status.values() if s == 'disrupted')\n",
    "    return affected_by_tier, total_output_loss, default_count, status\n",
    "\n",
    "affected, output_loss, defaults, final_status = simulate_disruption_cascade(\n",
    "    G, firm_data, disrupted_firm, threshold=0.5, max_tiers=4\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Visualization\n",
    "# ----------------------------\n",
    "pos = nx.spring_layout(G, seed=42, k=2.0, iterations=100)\n",
    "\n",
    "# Safely compute max_tier (avoid division by zero)\n",
    "max_tier = max(1, max(affected.keys()))  # ensures at least 1\n",
    "\n",
    "tier_color_map = {}\n",
    "for tier, firms in affected.items():\n",
    "    color = plt.cm.plasma(tier / max_tier)  # Now safe!\n",
    "    for f in firms:\n",
    "        tier_color_map[f] = color\n",
    "\n",
    "node_colors = [tier_color_map.get(node, (0.85, 0.85, 0.85, 1.0)) for node in G.nodes()]\n",
    "node_sizes = [200 + 3 * firm_data[node]['capacity'] / 10 for node in G.nodes()]\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(\n",
    "    G, pos,\n",
    "    edge_color='lightgray',\n",
    "    arrows=True,\n",
    "    arrowsize=10,\n",
    "    width=0.8,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Draw nodes\n",
    "nx.draw_networkx_nodes(\n",
    "    G, pos,\n",
    "    node_color=node_colors,\n",
    "    node_size=node_sizes,\n",
    "    alpha=0.95\n",
    ")\n",
    "\n",
    "# Label ALL disrupted firms\n",
    "disrupted_nodes = [n for n, s in final_status.items() if s == 'disrupted']\n",
    "nx.draw_networkx_labels(\n",
    "    G, pos,\n",
    "    labels={n: n for n in disrupted_nodes},\n",
    "    font_size=9,\n",
    "    font_weight='bold',\n",
    "    font_color='black'\n",
    ")\n",
    "\n",
    "# Legend\n",
    "legend_elements = [\n",
    "    Patch(facecolor=plt.cm.plasma(t / max_tier), label=f'Tier {t} (n={len(affected[t])})')\n",
    "    for t in sorted(affected.keys())\n",
    "]\n",
    "legend_elements.append(Patch(facecolor=(0.85, 0.85, 0.85), label='Unaffected'))\n",
    "plt.legend(handles=legend_elements, loc='upper right', title=\"Disruption Tier\")\n",
    "\n",
    "# Title\n",
    "total_capacity = sum(f['capacity'] for f in firm_data.values())\n",
    "loss_pct = (output_loss / total_capacity) * 100\n",
    "plt.title(\n",
    "    f\"Supply Chain Disruption Cascade (30 Firms)\\n\"\n",
    "    f\"Initial failure: {disrupted_firm} | \"\n",
    "    f\"{defaults}/{n_firms} firms disrupted ({loss_pct:.1f}% output loss)\",\n",
    "    fontsize=14,\n",
    "    pad=20\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Print Summary\n",
    "# ----------------------------\n",
    "print(f\"\\n=== CASCADE SUMMARY ===\")\n",
    "print(f\"Total firms: {n_firms}\")\n",
    "print(f\"Disrupted firms: {defaults} ({100 * defaults / n_firms:.1f}%)\")\n",
    "print(f\"Total output loss: {output_loss:.1f} units ({loss_pct:.1f}% of system capacity)\")\n",
    "print(\"\\nAffected by tier:\")\n",
    "for tier in sorted(affected.keys()):\n",
    "    print(f\"  Tier {tier}: {list(affected[tier])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b8d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Build Dense Supply Network (30 firms)\n",
    "# ----------------------------\n",
    "np.random.seed(123)\n",
    "n_firms = 30\n",
    "firm_names = [f\"Firm_{i}\" for i in range(n_firms)]\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(firm_names)\n",
    "\n",
    "# Increase connectivity to ensure cascade\n",
    "for i in range(n_firms):\n",
    "    num_customers = np.random.randint(3, 6)  # Each firm supplies 3â€“5 others\n",
    "    candidates = [f for f in firm_names if f != firm_names[i]]\n",
    "    if candidates:\n",
    "        customers = np.random.choice(candidates, size=min(num_customers, len(candidates)), replace=False)\n",
    "        for c in customers:\n",
    "            G.add_edge(firm_names[i], c)\n",
    "\n",
    "# Assign daily production capacity (output)\n",
    "firm_data = {firm: {'capacity': np.random.uniform(100, 600)} for firm in firm_names}\n",
    "\n",
    "# Assign supply dependency shares\n",
    "for customer in firm_names:\n",
    "    suppliers = list(G.predecessors(customer))\n",
    "    if suppliers:\n",
    "        weights = np.random.dirichlet(np.ones(len(suppliers)) * 1.5)\n",
    "        for i, supplier in enumerate(suppliers):\n",
    "            G[supplier][customer]['supply_share'] = weights[i]\n",
    "\n",
    "print(f\"Network: {G.number_of_nodes()} firms, {G.number_of_edges()} supply links\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Compute Centrality & Choose Disruption Target\n",
    "# ----------------------------\n",
    "pagerank = nx.pagerank(G, weight='supply_share', alpha=0.85)\n",
    "G_undir = G.to_undirected()\n",
    "betweenness = nx.betweenness_centrality(G_undir, weight='supply_share')\n",
    "\n",
    "# Pick firm with highest combined centrality\n",
    "combined_score = {f: pagerank[f] + betweenness[f] for f in firm_names}\n",
    "disrupted_firm = max(combined_score, key=combined_score.get)\n",
    "\n",
    "print(f\"\\nðŸ”¥ Disrupting: {disrupted_firm}\")\n",
    "print(f\"   PageRank: {pagerank[disrupted_firm]:.4f} | Betweenness: {betweenness[disrupted_firm]:.4f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Simulate Disruption Cascade\n",
    "# ----------------------------\n",
    "def simulate_disruption_cascade(G, firm_data, disrupted_firm, threshold=0.45, max_tiers=4):\n",
    "    status = {f: 'operational' for f in firm_names}\n",
    "    status[disrupted_firm] = 'disrupted'\n",
    "    affected_by_tier = {0: {disrupted_firm}}\n",
    "    newly_disrupted = {disrupted_firm}\n",
    "\n",
    "    for tier in range(1, max_tiers + 1):\n",
    "        next_disrupted = set()\n",
    "        for firm in newly_disrupted:\n",
    "            for customer in G.successors(firm):\n",
    "                if status[customer] != 'operational':\n",
    "                    continue\n",
    "                total_loss = sum(\n",
    "                    G[sup][customer].get('supply_share', 0)\n",
    "                    for sup in G.predecessors(customer)\n",
    "                    if status[sup] == 'disrupted'\n",
    "                )\n",
    "                if total_loss >= threshold:\n",
    "                    status[customer] = 'disrupted'\n",
    "                    next_disrupted.add(customer)\n",
    "        if not next_disrupted:\n",
    "            break\n",
    "        affected_by_tier[tier] = next_disrupted\n",
    "        newly_disrupted = next_disrupted\n",
    "\n",
    "    total_output_loss = sum(firm_data[f]['capacity'] for f in firm_names if status[f] == 'disrupted')\n",
    "    default_count = sum(1 for s in status.values() if s == 'disrupted')\n",
    "    return affected_by_tier, total_output_loss, default_count, status\n",
    "\n",
    "affected, total_loss, num_disrupted, final_status = simulate_disruption_cascade(\n",
    "    G, firm_data, disrupted_firm, threshold=0.45, max_tiers=4\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Print Detailed Disruption Report\n",
    "# ----------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ’¥ DISRUPTION IMPACT REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# List all disrupted firms with their output loss\n",
    "disrupted_list = []\n",
    "for firm in firm_names:\n",
    "    if final_status[firm] == 'disrupted':\n",
    "        loss = firm_data[firm]['capacity']\n",
    "        tier = next((t for t, firms in affected.items() if firm in firms), None)\n",
    "        disrupted_list.append({\n",
    "            'Firm': firm,\n",
    "            'Tier': tier,\n",
    "            'Daily Output Loss': loss\n",
    "        })\n",
    "\n",
    "# Create DataFrame for clean display\n",
    "df = pd.DataFrame(disrupted_list)\n",
    "df = df.sort_values(['Tier', 'Daily Output Loss'], ascending=[True, False])\n",
    "\n",
    "print(df.to_string(index=False, float_format=\"{:.1f}\".format))\n",
    "\n",
    "print(f\"\\nðŸ“ˆ TOTAL SYSTEM IMPACT:\")\n",
    "print(f\"   â€¢ Disrupted firms: {num_disrupted} / {n_firms} ({100 * num_disrupted / n_firms:.1f}%)\")\n",
    "print(f\"   â€¢ Total daily output loss: {total_loss:.1f} units\")\n",
    "total_capacity = sum(f['capacity'] for f in firm_data.values())\n",
    "print(f\"   â€¢ System-wide capacity loss: {100 * total_loss / total_capacity:.1f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Visualization\n",
    "# ----------------------------\n",
    "pos = nx.spring_layout(G, seed=42, k=2.5, iterations=100)\n",
    "\n",
    "# Safe max_tier to avoid division by zero\n",
    "max_tier = max(1, max(affected.keys()))\n",
    "\n",
    "tier_color_map = {}\n",
    "for tier, firms in affected.items():\n",
    "    color = plt.cm.plasma(tier / max_tier)\n",
    "    for f in firms:\n",
    "        tier_color_map[f] = color\n",
    "\n",
    "node_colors = [tier_color_map.get(node, (0.85, 0.85, 0.85, 1.0)) for node in G.nodes()]\n",
    "node_sizes = [200 + 3 * firm_data[node]['capacity'] / 10 for node in G.nodes()]\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, edge_color='lightgray', arrows=True, arrowsize=10, width=0.8, alpha=0.7)\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes, alpha=0.95)\n",
    "\n",
    "# Label ALL disrupted firms\n",
    "disrupted_nodes = [n for n, s in final_status.items() if s == 'disrupted']\n",
    "nx.draw_networkx_labels(G, pos, labels={n: n for n in disrupted_nodes}, font_size=9, font_weight='bold')\n",
    "\n",
    "# Legend\n",
    "legend_elements = [\n",
    "    Patch(facecolor=plt.cm.plasma(t / max_tier), label=f'Tier {t} (n={len(affected[t])})')\n",
    "    for t in sorted(affected.keys())\n",
    "]\n",
    "legend_elements.append(Patch(facecolor=(0.85, 0.85, 0.85), label='Unaffected'))\n",
    "plt.legend(handles=legend_elements, loc='upper right', title=\"Disruption Tier\")\n",
    "\n",
    "plt.title(\n",
    "    f\"Supply Chain Disruption: {disrupted_firm} Failed\\n\"\n",
    "    f\"{num_disrupted}/{n_firms} firms disrupted | {100 * total_loss / total_capacity:.1f}% output loss\",\n",
    "    fontsize=14, pad=20\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cafd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Build a sample supply chain network\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from([\n",
    "    (\"Supplier_X\", \"Manufacturer_A\"),\n",
    "    (\"Supplier_Y\", \"Manufacturer_A\"),\n",
    "    (\"Supplier_Z\", \"Manufacturer_B\"),\n",
    "    (\"Manufacturer_A\", \"Distributor_1\"),\n",
    "    (\"Manufacturer_B\", \"Distributor_1\"),\n",
    "    (\"Distributor_1\", \"Retailer_Final\"),\n",
    "])\n",
    "\n",
    "# 2. Compute centrality metrics\n",
    "pagerank = nx.pagerank(G, alpha=0.85)\n",
    "betweenness = nx.betweenness_centrality(G.to_undirected())  # Betweenness uses undirected paths\n",
    "\n",
    "# 3. Identify high-risk nodes (combine PageRank and Betweenness)\n",
    "critical_firms = sorted(\n",
    "    [(node, pr, betweenness[node]) for node, pr in pagerank.items()],\n",
    "    key=lambda x: (x[1] + x[2]),\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "print(\"Critical firms (High PageRank + High Betweenness):\")\n",
    "for firm, pr, bt in critical_firms[:3]:\n",
    "    print(f\"  {firm}: PageRank={pr:.3f}, Betweenness={bt:.3f}\")\n",
    "\n",
    "# Select the most critical firm to disrupt\n",
    "most_critical = critical_firms[0][0]\n",
    "print(f\"\\nâ†’ Simulating disruption of: {most_critical}\")\n",
    "\n",
    "# 4. Simulate disruption: remove the critical node\n",
    "G_disrupted = G.copy()\n",
    "if most_critical in G_disrupted:\n",
    "    G_disrupted.remove_node(most_critical)\n",
    "\n",
    "# Count affected downstream customers (nodes that lost at least one supplier)\n",
    "original_customers = set(n for n in G.nodes() if G.in_degree(n) > 0)\n",
    "remaining_customers = set(n for n in G_disrupted.nodes() if G_disrupted.in_degree(n) > 0)\n",
    "affected_count = len(original_customers - remaining_customers)\n",
    "\n",
    "print(f\"\\nAfter removing {most_critical}, number of affected customers: {affected_count}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5. VISUALIZATION\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# --- Left: Original Network ---\n",
    "plt.subplot(1, 2, 1)\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# Color the most critical node in red\n",
    "node_colors_orig = ['red' if node == most_critical else 'lightblue' for node in G.nodes()]\n",
    "nx.draw(\n",
    "    G, pos,\n",
    "    node_color=node_colors_orig,\n",
    "    node_size=1200,\n",
    "    with_labels=True,\n",
    "    font_size=10,\n",
    "    font_weight='bold',\n",
    "    arrows=True,\n",
    "    arrowsize=15,\n",
    "    edge_color='gray'\n",
    ")\n",
    "plt.title(f\"Original Supply Chain\\n(Red = Most Critical Node: {most_critical})\")\n",
    "\n",
    "# --- Right: Disrupted Network ---\n",
    "plt.subplot(1, 2, 2)\n",
    "# Keep same layout positions for comparable view (remove missing nodes)\n",
    "pos_disrupted = {node: pos[node] for node in G_disrupted.nodes() if node in pos}\n",
    "\n",
    "node_colors_disrupted = ['lightcoral' if G_disrupted.in_degree(node) == 0 and node != most_critical else 'lightblue'\n",
    "                         for node in G_disrupted.nodes()]\n",
    "\n",
    "nx.draw(\n",
    "    G_disrupted, pos_disrupted,\n",
    "    node_color=node_colors_disrupted,\n",
    "    node_size=1200,\n",
    "    with_labels=True,\n",
    "    font_size=10,\n",
    "    font_weight='bold',\n",
    "    arrows=True,\n",
    "    arrowsize=15,\n",
    "    edge_color='gray'\n",
    ")\n",
    "\n",
    "# Highlight orphaned customers (lost all suppliers)\n",
    "orphaned = [n for n in G_disrupted.nodes() if G_disrupted.in_degree(n) == 0]\n",
    "if orphaned:\n",
    "    nx.draw_networkx_nodes(\n",
    "        G_disrupted, pos_disrupted,\n",
    "        nodelist=orphaned,\n",
    "        node_color='orange',\n",
    "        node_size=1200\n",
    "    )\n",
    "\n",
    "plt.title(f\"After Removing {most_critical}\\n(Orange = Orphaned Customers)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309f34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Build a Larger, Layered Supply Chain Network\n",
    "# ----------------------------\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Define layers\n",
    "suppliers = [f\"Supplier_{i}\" for i in range(1, 6)]          # 5 suppliers\n",
    "manufacturers = [f\"Manufacturer_{i}\" for i in range(1, 5)]   # 4 manufacturers\n",
    "distributors = [f\"Distributor_{i}\" for i in range(1, 4)]     # 3 distributors\n",
    "retailers = [f\"Retailer_{i}\" for i in range(1, 6)]          # 5 retailers\n",
    "\n",
    "# Add all nodes\n",
    "all_nodes = suppliers + manufacturers + distributors + retailers\n",
    "G.add_nodes_from(all_nodes)\n",
    "\n",
    "# Connect suppliers â†’ manufacturers (each manufacturer uses 2â€“3 suppliers)\n",
    "import random\n",
    "random.seed(42)\n",
    "for m in manufacturers:\n",
    "    chosen_suppliers = random.sample(suppliers, k=random.randint(2, 3))\n",
    "    for s in chosen_suppliers:\n",
    "        G.add_edge(s, m)\n",
    "\n",
    "# Connect manufacturers â†’ distributors (each distributor gets from 2â€“3 manufacturers)\n",
    "for d in distributors:\n",
    "    chosen_manufacturers = random.sample(manufacturers, k=random.randint(2, 3))\n",
    "    for m in chosen_manufacturers:\n",
    "        G.add_edge(m, d)\n",
    "\n",
    "# Connect distributors â†’ retailers (each retailer served by 1â€“2 distributors)\n",
    "for r in retailers:\n",
    "    chosen_distributors = random.sample(distributors, k=random.randint(1, 2))\n",
    "    for d in chosen_distributors:\n",
    "        G.add_edge(d, r)\n",
    "\n",
    "print(f\"Network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Compute Centrality Metrics\n",
    "# ----------------------------\n",
    "pagerank = nx.pagerank(G, alpha=0.85)\n",
    "betweenness = nx.betweenness_centrality(G.to_undirected())\n",
    "\n",
    "# Combine scores to find most critical node\n",
    "combined_scores = {node: pagerank[node] + betweenness[node] for node in G.nodes()}\n",
    "most_critical = max(combined_scores, key=combined_scores.get)\n",
    "\n",
    "print(f\"\\nMost critical node: {most_critical}\")\n",
    "print(f\"  PageRank: {pagerank[most_critical]:.4f}\")\n",
    "print(f\"  Betweenness: {betweenness[most_critical]:.4f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Simulate Disruption\n",
    "# ----------------------------\n",
    "G_disrupted = G.copy()\n",
    "G_disrupted.remove_node(most_critical)\n",
    "\n",
    "# Count customers who lost ALL their suppliers (in-degree = 0) after disruption\n",
    "orphaned_after = [\n",
    "    n for n in G_disrupted.nodes()\n",
    "    if G_disrupted.in_degree(n) == 0 and n != most_critical\n",
    "]\n",
    "\n",
    "print(f\"\\nAfter removing {most_critical}:\")\n",
    "print(f\"  Orphaned nodes (no incoming supply): {len(orphaned_after)}\")\n",
    "if orphaned_after:\n",
    "    print(\"  Affected nodes:\", \", \".join(orphaned_after))\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Visualization\n",
    "# ----------------------------\n",
    "# Assign positions by layer for clarity\n",
    "# Assign positions by layer for clarity\n",
    "pos = {}\n",
    "layer_spacing = 3\n",
    "\n",
    "# Each entry: (list_of_nodes, y_level)\n",
    "layers = [\n",
    "    (suppliers, 0),\n",
    "    (manufacturers, 1),\n",
    "    (distributors, 2),\n",
    "    (retailers, 3)\n",
    "]\n",
    "\n",
    "for node_list, y_level in layers:\n",
    "    n = len(node_list)\n",
    "    # Center the group horizontally\n",
    "    x_positions = [i * layer_spacing for i in range(n)]\n",
    "    x_center = (n - 1) * layer_spacing / 2\n",
    "    for i, node in enumerate(node_list):\n",
    "        pos[node] = (x_positions[i] - x_center, y_level)\n",
    "        \n",
    "# --- Plot Original vs Disrupted ---\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Original Network\n",
    "plt.subplot(1, 2, 1)\n",
    "node_colors_orig = ['red' if node == most_critical else 'lightblue' for node in G.nodes()]\n",
    "nx.draw(\n",
    "    G, pos,\n",
    "    node_color=node_colors_orig,\n",
    "    node_size=900,\n",
    "    with_labels=True,\n",
    "    font_size=8,\n",
    "    font_weight='bold',\n",
    "    arrows=True,\n",
    "    arrowsize=12,\n",
    "    edge_color='gray',\n",
    "    width=1.0\n",
    ")\n",
    "plt.title(f\"Original Supply Chain\\n(Red = Most Critical: {most_critical})\")\n",
    "\n",
    "# Disrupted Network\n",
    "plt.subplot(1, 2, 2)\n",
    "# Reuse same positions (skip missing node)\n",
    "pos_disrupted = {n: pos[n] for n in G_disrupted.nodes()}\n",
    "\n",
    "node_colors_disrupted = []\n",
    "for node in G_disrupted.nodes():\n",
    "    if node in orphaned_after:\n",
    "        node_colors_disrupted.append('orange')      # lost all supply\n",
    "    elif G_disrupted.out_degree(node) == 0 and G_disrupted.in_degree(node) > 0:\n",
    "        node_colors_disrupted.append('lightgreen')  # end customer (retailer)\n",
    "    else:\n",
    "        node_colors_disrupted.append('lightblue')\n",
    "\n",
    "nx.draw(\n",
    "    G_disrupted, pos_disrupted,\n",
    "    node_color=node_colors_disrupted,\n",
    "    node_size=900,\n",
    "    with_labels=True,\n",
    "    font_size=8,\n",
    "    font_weight='bold',\n",
    "    arrows=True,\n",
    "    arrowsize=12,\n",
    "    edge_color='gray',\n",
    "    width=1.0\n",
    ")\n",
    "\n",
    "# Add legend manually\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='red', label='Removed Node'),\n",
    "    Patch(facecolor='orange', label='Orphaned (No Input)'),\n",
    "    Patch(facecolor='lightgreen', label='End Customer'),\n",
    "    Patch(facecolor='lightblue', label='Operational')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.title(f\"After Removing {most_critical}\\n(Orange = Orphaned Nodes)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
